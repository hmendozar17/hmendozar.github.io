# Probability Review {#intro}


In This chapter we introduce probability concepts to deal with uncertainty. Stochastic simulations requiere probability as an essential tool. Simulations are very useful in situations that are too complex to analyse theoretically. In this chapter we cover
\begin{comment}
 henry paragraph
\end{comment}


- Random Experiments

- Sample Spaces

- Sigma Algebra

- Events

- The probability axioms

- Computing probabilities: Countable sample space


- Conditional probability

- Independence

- The Law of Total Probability

- Bayesâ€™ theorem


## Probability Axioms
There are four techniques approach to determine propbailities
- Relative Frequency 
- Subjective
- Classical (or Laplace or equally-likely)
- Axiomatic (Kolmogorov)

### Random experiment and Sample Space
<div class="alert alert-warning"><small>
```{definition,name="A random (or statistical) experiment"}
is an experiment in which

a. all outcomes of the experiment are known in advance.

b. any performance of the experiment results in an outcome that is not know in advance

c. the experiment can be repeated under identical conditions
```
</small>
</div>



```{example,name="Examples of Random experiment"}

1. One flip of a coin

2. Flip a coin n times

3. Toss a coin repeatedly until a head appears and record the number of tosses requiered

4. Toss a coin repeatedly until a  3 heads appears and record the number of tosses requiered

5. Select a light bulb and register its lifetime
```


<div class="alert alert-warning"><small>
```{definition,name="Sample space"}
is the set of all possible outcomes. It is denoted by $\Omega$
```
</small>
</div>

```{example,name="Examples of Sample space"}

1. One flip of a coin: $\Omega=\{T,H\}$
  
2. Flip a coin 2 times: $\Omega=\{(H,H),(H,T),(T,H),(T,T)\}$
  
3. Toss a coin repeatedly until a head appears and record the number of tosses requiered: $\Omega=\{1,2,3,\ldots\}$
  
4. Toss a coin repeatedly until a  3 heads appears and record the number of tosses requiered: $\Omega=\{3,4,5,\ldots\}$
  
5. Select a light bulb and register its lifetime: $\Omega=\{x:x>0\}$
```



<div class="alert alert-success"><small>
**Note**

- The elements of $\Omega$ are called sample points.

- An event is any set $A\in \mathcal{A}$ where
$A=\{\omega\in\Omega\}$

- if $A=\Omega$ is called **sure event**, if  $A=\emptyset$ is called **impossible  event**, and if $A=\{ \omega\}$ is called **elemental event**.
- any event $A$ with $P(A)=0$ is called null event.
- we say that an event $A$ happens if the outcome of the experiment corresponds to a point in $A$.
- we said that the events $A$ and $B$ are disjoint if and only if $A\cap B=\emptyset$.
</small></div>

## Types of Sample space
The sample space $\Omega$ is called: 

- **Finite or Countable finite sample space** if it contains only Finite or Countably finite number of points.
- **Discrete or Countable infinite sample space** if it contains at most   number of points.
- **Uncountable  sample space** if it contains uncountably many points. In particular if $\Omega=\mathbb{R}^{n}$  or some rectangle in $\mathbb{R}^{n}$, we call it a **Continuous sample space**.


## Events: Which Sigma-algebra is associated with each type of sample space?

<div class="alert alert-warning"><small>
```{definition,name="Sigma-algebra"}

Let $\Omega\neq \emptyset$ y  $\mathcal{A}$ a non-empty colecction of subsets in $\Omega$ such that
  
1. $\Omega\in$$\mathcal{A}$
  
2. If $A\in\mathcal{A}$, then 
$$\overline{A}\in\textbf{A}$$
3. If $A_{1},A_{2},\ldots\in$$\mathcal{A}$ then
$$\cup_{n=1}^{\infty}A_{n}\in\mathcal{A}$$

```
</small>
</div>

<div class="alert alert-success"><small>
Note: 

- Any set in  $\mathcal{A}$ is caled **event**

- If $\Omega$ is discrete or finite, we can always take $\mathcal{A}$ to be the class of all subsets of $\Omega$;i.e., $\mathcal{A}=\mathcal{P}(\Omega)=2^{\Omega}$. Then every subset of $\Omega$ is an event.

- If $\Omega$ is a uncountable set, we can assign the Borel sigma algebra; $\mathcal{B}(\mathbb{R})$ 
</small>
</div>
## Axiomatic definition of Probability
<div class="alert alert-warning"><small>
```{definition, name="Probability"}

Let $(\Omega,\mathcal{A})$ be measurable space associate with statistical experiment. A set function $P$ defined on $\mathcal{A}$, that is,
$P:\mathcal{A} \rightarrow\mathcal{R}$
  
  is called *probability measure* (or simply, *probability* if it satisfies the following conditions:
                                     

  1. $P(A)\geq 0$ $\forall A \in \mathcal{A}$
    
  2. $P(\Omega)=1$.
  
  3. Let $\{A_1,A_2,\ldots\}$ be a collection of disjoint sets in $\mathcal{A}$;that is, $A_i\cap A_j\neq\emptyset$, for $i\neq j$, where  $\emptyset$ is the empty set. Then
  
  $$ P(\bigcup \limits_{i=1}^{\infty} A_i)=\sum_{i=1}^{\infty}P(A_i)$$

```
</small>
</div>

<div class="alert alert-warning"><small>
```{definition, name="Probability Space"}
The triple $(\Omega,\mathcal{F},P)$ is called a probability space.
```
</small>
</div>

## Properties of Probability
```{theorem, name="Monotony"}
The measure $P$ is no decreasing for $A$ and $B$ events. If $A$ $\subseteq$ B, then 
\begin{equation}
P(A)\leq P(B) \; \text{and} 
\;P(B-A)=P(B)-P(A).
\end{equation}
```


```{theorem, name="Addition Rule"}
if $A, B \in F$, then 

$$P(A \cup B)=P(A)+P(B)-P(A\cap B$$
```

```{corollary, name="Complement Rule"}
If $A\in F$, then  
$$P(A^c)=1-P(A)$$
```


Notice that $P(\emptyset)=0$ follows from the last corollary.

```{theorem, name="Principle of Inclusion-Exclusion"}
If $A_1$, $A_2$, $A_3$, $\ldots$, $A_n$ $\in$ $\mathcal{A}$ are pairwise disjoint events, then

\begin{align}
P(\bigcup \limits_{j=1}^{n}A_j)&=\sum \limits_{j=1}^{n}P(A_j)-\sum \limits_{1\leq i<j\leq n}P(A_i \cap A_j)\\
&=\sum \limits_{1\le i<j<k\le n}P(A_i\cap A_j \cap A_k)-\cdots + (-1)^{n+1}P(A_1\cap A_2 \cap \ldots \cap A_n)
\end{align}
```

## How to assign P(A)?
The last definition give us the condition that the function $P$ require to be a probability but it did not mention about how to define the rule, $P(A)$. There are different ways to define it, depending of the sample space, $\Omega$.



### Countable finite 

If $\Omega$ is countable then we can always assign a probability to all of its subsets.

1. Assign any non-neagtive number $p(\omega)$ for each element $w$ in $\Omega$ such that the sum of all values $p(\omega)$ is 1.

2. Compute probability such as
$$
 \bbox[yellow,5px,border:2px solid red]
{
P(A)=\frac{\text {Number of elements in A}}{|\Omega|}
}
$$

```{example, name="A not unbiased coin"}
Suppose we flip a coin $r$ times. We will consider two cases: 
  
-  the coin is not unbiased, and 

- the coin is unbiased with probability of getting head, $p\neq\frac{1}{2}$, and $(0\leq p \leq 1)$
  
```



Suppose a not unbiased coin in throw r times.
In this case we can assign the same probability value for each value in the sample space. So
\[
P(\omega)=\frac{1}{2^r}
\]
for all $w\in\Omega$.  This imply that to find the probability of any event $A\in \mathcal P (\Omega)$ we will use the formula given above for $P(A)$

- What is the probability that no head will show up in $r$ throws?. 
Let the event 

$$
A:\text{''no head in $r$ throws"}\iff A=\{(T,T,\cdots,T)\}
$$
then 

$$
P(A)=\frac{|A|}{|\Omega|}=\frac{1}{2^r}
$$

## Conditional Probability

<div class="alert alert-warning"><small>
```{definition,name="Conditional Probability"}
Let $(\Omega,\mathcal{F},P)$ be  a probability space, and let $B\in \mathcal{A}$ with $P(B)>0$. For any $A\in \mathcal{F}$. The conditional probability of $A$, given $B$ is defined by:
$$
P(A\mid B)=\frac{P(A\cap B)}{P(B)}
$$
```
</small>
</div>

## Multiplication Rule
```{theorem, name="Multiplication Rule"}
Let $(\Omega,\mathcal{F},P)$ be  a probability space, and $A_1,A_2,\ldots,A_n\in\mathcal{F}$, with $P(A_1\cap A_2\cap \ldots \cap A_{n-1})>0$, Then 
 $$P(A_1\cap A_2\cap \cdots \cap A_{n})=P(A_1)P(A_2\mid A_1)P(A_3\mid A_2\cap A_1)\cdots P(A_n\mid A_1\cap A_2\cap \cdots \cap A_{n-1})$$
```
Notice that in the case of two events, $A_1$ and $A_2$ two events with $P(A_1)>0$ and $P(A_2)>0$. Then it follows that 
$$
P(A_1\cap A_2)=P(A)P(A_2\mid A_1)
$$
and 
$$
P(A_1\cap A_2)=P(A_2)P(A_1\mid A_2)
$$
